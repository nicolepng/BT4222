{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import zipfile\n",
    "import requests\n",
    "import gdown\n",
    "import pickle\n",
    "import io\n",
    "from datetime import date\n",
    "from pyura import Client\n",
    "from requests import Session\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-set Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_mapping = {\n",
    "    \"1\" : [\"RAFFLES PLACE MRT STATION EXIT A\", \"CECIL BUILDING\", \"MARINA BAY SINGAPORE\", \"PEOPLE'S PARK COMPLEX\"],\n",
    "    \"2\" : [\"ANSON ROAD\", \"TANJONG PAGAR MRT STATION EXIT A\"],\n",
    "    \"3\" : [\"QUEENSTOWN MRT STATION EXIT A\", \"TIONG BAHRU MRT STATION EXIT A\"],\n",
    "    \"4\" : [\"TELOK BLANGAH RISE MARKET\", \"HARBOURFRONT MRT STATION EXIT A\"],\n",
    "    \"5\" : [\"PASIR PANJANG MRT STATION EXIT A\", \"CLEMENTI MRT STATION EXIT A\"],\n",
    "    \"6\" : [\"HIGH STREET PLAZA\", \"CALTEX BEACH ROAD\"],\n",
    "    \"7\" : [\"DBS MIDDLE ROAD 210\", \"GOLDEN MILE COMPLEX\"],\n",
    "    \"8\" : [\"LITTLE INDIA MRT STATION EXIT A\"],\n",
    "    \"9\" : [\"ORCHARD MRT STATION EXIT A\", \"THE CAIRNHILL\", \"GREAT WORLD MRT STATION\"],\n",
    "    \"10\" : [\"BUKIT TIMAH ROAD\", \"HOLLAND VILLAGE MRT STATION\", \"TANGLIN MALL\"],\n",
    "    \"11\" : [\"WATTEN ESTATE\", \"NOVENA MRT STATION EXIT A\", \"THOMSON PLAZA\"],\n",
    "    \"12\" : [\"BALESTIER PLAZA\", \"TOA PAYOH MRT STATION EXIT A\", \"SERANGOON MRT STATION EXIT A\"],\n",
    "    \"13\" : [\"MACPHERSON MRT STATION EXIT A\", \"BRADDELL MRT STATION EXIT A\"],\n",
    "    \"14\" : [\"PAYA LEBAR MRT STATION EXIT A\", \"EUNOS MRT STATION EXIT A\"],\n",
    "    \"15\" : [\"TANJONG KATONG GIRLS' SCHOOL\", \"KOON SENG PARK\", \"TANJONG KATONG MRT STATION EXIT A\"],\n",
    "    \"16\" : [\"BEDOK MRT STATION EXIT A\", \"TANAH MERAH MRT STATION EXIT A\", \"SUNGEI BEDOK MRT STATION\", \"KEW DRIVE PLAYGROUND\"],\n",
    "    \"17\" : [\"MARIAM WAY PLAYGROUND\", \"KEMBANGAN MRT STATION EXIT A\"],\n",
    "    \"18\" : [\"TAMPINES MRT STATION EXIT A\", \"PASIR RIS MRT STATIONEXIT A\"],\n",
    "    \"19\" : [\"SERANGOON GARDEN MARKET EXIT A\", \"HOUGANG MRT STATION EXIT A\", \"PUNGGOL MRT STATION EXIT A\"],\n",
    "    \"20\" : [\"BISHAN MRT STATION EXIT A\", \"ANG MO KIO MRT STATION EXIT A\"],\n",
    "    \"21\" : [\"ESSO UPPER BUKIT TIMAH A\", \"CLEMENTI PARK\", \"ULU PANDAN COMMUNITY CLUB\"],\n",
    "    \"22\" : [\"JURONG EAST MRT STATION EXIT A\", \"BOON LAY MRT STATION EXIT A\", \"LAKESIDE MRT STATION EXIT A\", \"CHINESE GARDEN MRT STATION EXIT A\"],\n",
    "    \"23\" : [\"HILLVIEW MRT STATION EXIT A\", \"GERMAN EUROPEAN SCHOOL SINGAPORE\", \"BUKIT PANJANG MRT STATION EXIT A1\", \"CHOA CHU KANG MRT STATION EXIT A\"],\n",
    "    \"24\" : [\"LIM CHU KANG CAMP I\", \"GARDEN VALE @ TENGAH\"],\n",
    "    \"25\" : [\"KRANJI MRT STATION EXIT A\", \"THE WOODGROVE\"],\n",
    "    \"26\" : [\"UPPER THOMSON MRT STATION\", \"SPRINGLEAF GARDEN\"],\n",
    "    \"27\" : [\"YISHUN MRT STATION EXIT A\", \"SEMBAWANG MRT STATION EXIT A\"],\n",
    "    \"28\" : [\"THE SELETAR MALL\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_postal = {\n",
    "    \"1\" : [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\"],\n",
    "    \"2\" : [\"07\", \"08\"],\n",
    "    \"3\" : [\"14\", \"15\", \"16\"],\n",
    "    \"4\" : [\"09\", \"10\"],\n",
    "    \"5\" : [\"11\", \"12\", '13'],\n",
    "    \"6\" : [\"17\"],\n",
    "    \"7\" : [\"18\", \"19\"],\n",
    "    \"8\" : [\"20\", \"21\"],\n",
    "    \"9\" : [\"22\", \"23\"],\n",
    "    \"10\" : [\"24\", \"25\", \"26\", \"27\"],\n",
    "    \"11\" : [\"28\", \"29\", \"30\"],\n",
    "    \"12\" : [\"31\", \"32\", \"33\"],\n",
    "    \"13\" : [\"34\", \"35\", \"36\", \"37\"],\n",
    "    \"14\" : [\"38\", \"39\", \"40\", \"41\"],\n",
    "    \"15\" : [\"42\", \"43\", \"44\", \"45\"],\n",
    "    \"16\" : [\"46\", \"47\", \"48\"],\n",
    "    \"17\" : [\"49\", \"50\", \"81\"],\n",
    "    \"18\" : [\"51\", \"52\"],\n",
    "    \"19\" : [\"53\", \"54\", \"55\", \"82\"],\n",
    "    \"20\" : [\"56\", \"57\"],\n",
    "    \"21\" : [\"58\", \"59\"],\n",
    "    \"22\" : [\"60\", \"61\", \"62\", \"63\", \"64\"],\n",
    "    \"23\" : [\"65\", \"66\", \"67\", \"68\"],\n",
    "    \"24\" : [\"69\", \"70\", \"71\"],\n",
    "    \"25\" : [\"72\", \"73\"],\n",
    "    \"26\" : [\"77\", \"78\"],\n",
    "    \"27\" : [\"75\", \"76\"],\n",
    "    \"28\" : [\"79\", \"80\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_floors = {\n",
    "    '01 TO 03' : '01-05',\n",
    "    '04 TO 06' : '01-05',\n",
    "    '07 TO 09' : '06-10',\n",
    "    '10 TO 12' : '11-15',\n",
    "    '13 TO 15' : '11-15',\n",
    "    '16 TO 18' : '16-20',\n",
    "    '19 TO 21' : '16-20',\n",
    "    '22 TO 24' : '21-25',\n",
    "    '25 TO 27' : '26-30',\n",
    "    '28 TO 30' : '26-30',\n",
    "    '31 TO 33' : '31-35',\n",
    "    '34 TO 36' : '31-35',\n",
    "    '37 TO 39' : '36-40',\n",
    "    '40 TO 42' : '41-45',\n",
    "    '43 TO 45' : '41-45',\n",
    "    '46 TO 48' : '46-50',\n",
    "    '-' : '-'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import CSVs needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_stops_url = 'https://raw.githubusercontent.com/nicolepng/BT4222/main/Data/bus_stops.csv' \n",
    "bus_stops = pd.read_csv(bus_stops_url)\n",
    "bus_stops.drop(bus_stops.columns[0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "amenities_url = 'https://raw.githubusercontent.com/nicolepng/BT4222/main/Data/ameneties_per_district.csv' \n",
    "ameneties_per_district = pd.read_csv(amenities_url)\n",
    "ameneties_per_district.drop(ameneties_per_district.columns[0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_crime_locations_url = 'https://raw.githubusercontent.com/nicolepng/BT4222/main/Data/average_crimes_by_location_v3.csv' \n",
    "average_crimes_by_location_v3 = pd.read_csv(avg_crime_locations_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# swap dictionary mapping direction\n",
    "postal_district = {k: oldk for oldk, oldv in district_postal.items() for k in oldv}\n",
    "\n",
    "# create new column to obtain the 1st 2 characters of [Postal]\n",
    "average_crimes_by_location_v3['postal prefix'] = average_crimes_by_location_v3['Postal'].astype(str).str[0:2]\n",
    "\n",
    "# map postal to district code\n",
    "average_crimes_by_location_v3['district']= average_crimes_by_location_v3['postal prefix'].map(postal_district) \n",
    "\n",
    "# get overall crime rate in each district\n",
    "average_crimes_by_location_v3 = average_crimes_by_location_v3.groupby(['district']).agg({'Number':'sum'}).reset_index()\n",
    "\n",
    "district_int = average_crimes_by_location_v3.district.astype(int)\n",
    "district_int = pd.DataFrame(district_int)\n",
    "average_crimes_by_location_v3['district'] = district_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district_num</th>\n",
       "      <th>weighted_sentiment</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.082516</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.317045</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.123678</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.093259</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>24</td>\n",
       "      <td>0.150795</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>25</td>\n",
       "      <td>0.088860</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>26</td>\n",
       "      <td>-0.025054</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>27</td>\n",
       "      <td>0.084183</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>28</td>\n",
       "      <td>0.133119</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     district_num  weighted_sentiment  year\n",
       "0              21            0.000000  2018\n",
       "1               1            0.082516  2018\n",
       "2               2            0.317045  2018\n",
       "3               3            0.123678  2018\n",
       "4               4            0.093259  2018\n",
       "..            ...                 ...   ...\n",
       "107            24            0.150795  2021\n",
       "108            25            0.088860  2021\n",
       "109            26           -0.025054  2021\n",
       "110            27            0.084183  2021\n",
       "111            28            0.133119  2021\n",
       "\n",
       "[112 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_url = 'https://raw.githubusercontent.com/nicolepng/BT4222/main/Data/combined_sentiment.csv' \n",
    "sentiment = pd.read_csv(sentiment_url)\n",
    "sentiment = sentiment[['district_num','hwz_sentiment','year']]\n",
    "sentiment.columns = ['district_num', 'weighted_sentiment', 'year']\n",
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/u/0/uc?id=1qfTQF5-76kKzu_ipm06HtUV-75cT44pV\n",
      "To: /Users/admin/Desktop/Y3S2/BT4222/BT4222/finalized_model.sav\n",
      "2.72GB [01:09, 39.1MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'finalized_model.sav'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import model\n",
    "url = 'https://drive.google.com/u/0/uc?id=1qfTQF5-76kKzu_ipm06HtUV-75cT44pV'\n",
    "output = 'finalized_model.sav'\n",
    "# gdown.download(url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions needed to get input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get district number\n",
    "def get_postal_onemap(place, district_postal):\n",
    "    start_code= \"https://developers.onemap.sg/commonapi/search?returnGeom=Y&getAddrDetails=Y&pageNum=1&searchVal=\"+ str(\"Ang Mo Kio Ave 5\")\n",
    "    s_response = requests.get(start_code)\n",
    "    s_data = json.loads(s_response.text)\n",
    "    postal = None\n",
    "    count = 0\n",
    "    while postal is None:\n",
    "        count += 1\n",
    "        if count == 10:\n",
    "            postal = None\n",
    "            break\n",
    "        for i in range(len(s_data['results'])):\n",
    "            postal = s_data['results'][i]['POSTAL']\n",
    "            try:\n",
    "                postal = int(postal)\n",
    "            except:\n",
    "                continue\n",
    "    for district, sub_dist in district_postal.items():\n",
    "        if str(postal)[:2] in sub_dist:\n",
    "            dist = district\n",
    "    try:\n",
    "        return dist\n",
    "    except:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get latitude and longitude\n",
    "def get_lat_long(street):\n",
    "    geolocator = Nominatim(user_agent=\"newtestuserbtproj\")\n",
    "    location = geolocator.geocode({\"street\": street, \"country\": \"Singapore\"})\n",
    "    coordinates = [location.latitude, location.longitude]\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get number of bus stops\n",
    "# Formula to calculate distance \n",
    "from math import cos, sqrt\n",
    "R = 6371000 #radius of the Earth in m\n",
    "def distance(lon1, lat1, lon2, lat2):\n",
    "    x = (lon2 - lon1) * cos(0.5*(lat2+lat1))\n",
    "    y = (lat2 - lat1)\n",
    "    return R * sqrt( x*x + y*y )\n",
    "\n",
    "def num_of_bus_stops(lat, long):\n",
    "    busStops = bus_stops.to_dict(orient='records')\n",
    "    # threshold of within 1km\n",
    "    numOfStops = []\n",
    "    buslist = list(filter(lambda d: distance(d[\"Longitude\"], d[\"Latitude\"], long, lat) <= 1000, busStops))\n",
    "    return len(buslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get num of schools\n",
    "def num_schools(district):\n",
    "    sch_list = ameneties_per_district.loc[ameneties_per_district['district'] == district]['school'].item()\n",
    "    num_sch = sch_list.strip('][').split(',') \n",
    "    if \" SINGAPORE'\" in num_sch:\n",
    "        num_sch.remove(\" SINGAPORE'\")\n",
    "    return len(num_sch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get num of supermarkets\n",
    "def num_supermarkets(district):\n",
    "    market_list = ameneties_per_district.loc[ameneties_per_district['district'] == district]['supermarkets'].item()\n",
    "    num_market = market_list.strip('][').split(',') \n",
    "    return len(num_market)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get num of hawker\n",
    "def num_hawker(district):\n",
    "    hawker_list = ameneties_per_district.loc[ameneties_per_district['district'] == district]['hawkercentre'].item()\n",
    "    num_hawker = hawker_list.strip('][').split(',') \n",
    "    return len(num_hawker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get crime number \n",
    "def crime_num(district):\n",
    "    return average_crimes_by_location_v3[average_crimes_by_location_v3.district == district].Number.item() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sentiment score\n",
    "def sentiment_score(district, year):\n",
    "    return sentiment[(sentiment.district_num == district) & (sentiment.year == year)].weighted_sentiment.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get floor range\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actual Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "district  \n",
    "street             \n",
    "propertyType        \n",
    "remaining_lease   \n",
    "price              \n",
    "school             \n",
    "hawkercentre        \n",
    "supermarkets       \n",
    "Bus Stops Nearby   \n",
    "crime_number        \n",
    "latitude          \n",
    "longitude           \n",
    "floor_area_sqm     \n",
    "floor_range        \n",
    "sentiment\n",
    "Street given, propertyType given, remaining lease given, square feet also given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Street Name: Jalan Khamis\n",
      "Enter Type of Property: Semi-detached\n",
      "Enter num of years left: 999\n",
      "Area of House (Square Metres): 334.5\n",
      "Enter Floor Range: -\n",
      "Current Year? 2021\n"
     ]
    }
   ],
   "source": [
    "street = input(\"Enter Street Name: \")\n",
    "\n",
    "propertyType = input(\"Enter Type of Property: \")\n",
    "\n",
    "remaining_lease = int(input(\"Enter num of years left: \"))\n",
    "\n",
    "floor_area_sqm = input(\"Area of House (Square Metres): \")\n",
    "\n",
    "floor_range = input(\"Enter Floor Range: \")\n",
    "\n",
    "year = int(input(\"Current Year? \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "district = get_postal_onemap(street, district_postal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all details \n",
    "#district = get_postal_onemap(street, district_postal)\n",
    "coordinates = get_lat_long(street)\n",
    "latitude = coordinates[0]\n",
    "longitude = coordinates[1]\n",
    "school = num_schools(int(district))\n",
    "hawkercentre = num_hawker(int(district))\n",
    "supermarkets = num_supermarkets(int(district))\n",
    "bus_stops_nearby = num_of_bus_stops(latitude, longitude)\n",
    "crime_number = crime_num(int(district))\n",
    "score = sentiment_score(int(district), year)\n",
    "floor_range = replace_floors.get(floor_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temp dataframe to fit into model\n",
    "temp_column_names = ['district', 'street', 'propertyType', 'remaining_lease',\n",
    "                    'school', 'hawkercentre', 'supermarkets', 'Bus Stops Neaby',\n",
    "                    'crime_number', 'latitude', 'longitude', 'floor_area_sqm', 'floor_range',\n",
    "                    'sentiment']\n",
    "temp = pd.DataFrame(columns = temp_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>district</th>\n",
       "      <th>street</th>\n",
       "      <th>propertyType</th>\n",
       "      <th>remaining_lease</th>\n",
       "      <th>school</th>\n",
       "      <th>hawkercentre</th>\n",
       "      <th>supermarkets</th>\n",
       "      <th>Bus Stops Neaby</th>\n",
       "      <th>crime_number</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>floor_range</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>Jalan Khamis</td>\n",
       "      <td>Semi-detached</td>\n",
       "      <td>999</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>122.714286</td>\n",
       "      <td>1.353818</td>\n",
       "      <td>103.837695</td>\n",
       "      <td>334.5</td>\n",
       "      <td>-</td>\n",
       "      <td>0.082217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  district        street   propertyType remaining_lease school hawkercentre  \\\n",
       "0       20  Jalan Khamis  Semi-detached             999     37           11   \n",
       "\n",
       "  supermarkets Bus Stops Neaby  crime_number  latitude   longitude  \\\n",
       "0            5               0    122.714286  1.353818  103.837695   \n",
       "\n",
       "  floor_area_sqm floor_range  sentiment  \n",
       "0          334.5           -   0.082217  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.append({'district': district, 'street': street, 'propertyType': propertyType, \n",
    "             'remaining_lease': remaining_lease,'school': school, 'hawkercentre': hawkercentre, \n",
    "             'supermarkets': supermarkets, 'Bus Stops Neaby': bus_stops_nearby,\n",
    "            'crime_number': crime_number, 'latitude': latitude, \n",
    "             'longitude': longitude, 'floor_area_sqm': floor_area_sqm, 'floor_range': floor_range,\n",
    "            'sentiment': score\n",
    "}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator KNeighborsRegressor from version 0.22.2.post1 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator LinearRegression from version 0.22.2.post1 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 0.22.2.post1 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator RandomForestRegressor from version 0.22.2.post1 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator StackingRegressor from version 0.22.2.post1 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "# loaded_model = pickle.load(open('finalized_model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['street'] = temp['street'].astype('category')\n",
    "street_dict = dict(zip(temp['street'].cat.codes, temp['street']))\n",
    "temp['street'] = temp['street'].cat.codes\n",
    "\n",
    "temp['propertyType'] = temp['propertyType'].astype('category')\n",
    "property_dict = dict(zip(temp['propertyType'].cat.codes, temp['propertyType']))\n",
    "temp['propertyType'] = temp['propertyType'].cat.codes\n",
    "\n",
    "temp['floor_range'] = temp['floor_range'].astype('category')\n",
    "floor_dict = dict(zip(temp['floor_range'].cat.codes, temp['floor_range']))\n",
    "temp['floor_range'] = temp['floor_range'].cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 14)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-dc40120c32dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         return self.final_estimator_.predict(\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         )\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0mPrediction\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         \"\"\"\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sk_visual_block_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;34m\"\"\"Concatenate and return the predictions of the estimators.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         predictions = [\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack_method_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         predictions = [\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack_method_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'drop'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/neighbors/_regression.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mTarget\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \"\"\"\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    649\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             raise ValueError(\"Found array with %d sample(s) (shape=%s) while a\"\n\u001b[0m\u001b[1;32m    652\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m                              % (n_samples, array.shape, ensure_min_samples,\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 14)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "loaded_model.predict(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
